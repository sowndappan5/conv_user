<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>One-on-One Audio Call</title>
    <link rel="stylesheet" href="static/styles.css">
</head>
<body>
    <div class="container">
        <h1>One-on-One Audio Call</h1>
        <button id="startCall">Start Call</button>
        <audio id="remoteAudio" autoplay></audio>
        <p id="status">Waiting for a user...</p>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/peerjs/1.3.1/peerjs.min.js"></script>
    <script src="static/script.js"></script>
</body>
<style>
    body {
    font-family: Arial, sans-serif;
    text-align: center;
    background-color: #f4f4f4;
}

.container {
    width: 300px;
    margin: 100px auto;
    padding: 20px;
    background: white;
    box-shadow: 0px 0px 10px gray;
    border-radius: 10px;
}

button {
    padding: 10px 20px;
    font-size: 16px;
    margin-top: 10px;
    cursor: pointer;
    background: #007bff;
    color: white;
    border: none;
    border-radius: 5px;
}

button:hover {
    background: #0056b3;
}

</style>
<script>
const BACKEND_URL = "https://your-app.onrender.com"; // Replace with your Render backend URL
const startCallButton = document.getElementById("startCall");
const statusText = document.getElementById("status");
const remoteAudio = document.getElementById("remoteAudio");
let peer;
let myPeerId;
let connectedPeerId;

startCallButton.addEventListener("click", async () => {
    try {
        // Get a unique Peer ID from the backend
        const response = await fetch(`${BACKEND_URL}/get_peer_id`);
        const data = await response.json();
        myPeerId = data.peer_id;

        // Initialize PeerJS with the generated Peer ID
        peer = new Peer(myPeerId);

        peer.on("open", (id) => {
            statusText.innerText = `Your ID: ${id}. Waiting for a match...`;
            findPeer();
        });

        peer.on("call", (call) => {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then((stream) => {
                    call.answer(stream); // Answer the incoming call
                    call.on("stream", (remoteStream) => {
                        remoteAudio.srcObject = remoteStream;
                        statusText.innerText = "Connected!";
                    });
                });
        });
    } catch (error) {
        console.error("Error:", error);
    }
});

// Function to find an available peer
async function findPeer() {
    const response = await fetch(`${BACKEND_URL}/find_peer`);
    const data = await response.json();

    if (data.peer_id) {
        connectedPeerId = data.peer_id;
        connectToPeer(connectedPeerId);
    } else {
        statusText.innerText = "Waiting for another user...";
    }
}

// Function to connect to a peer and start audio call
function connectToPeer(peerId) {
    navigator.mediaDevices.getUserMedia({ audio: true })
        .then((stream) => {
            const call = peer.call(peerId, stream);
            call.on("stream", (remoteStream) => {
                remoteAudio.srcObject = remoteStream;
                statusText.innerText = "Connected!";
            });
        });
}

// Function to moderate audio using Gemini AI
async function moderateAudio(audioText) {
    const response = await fetch(`${BACKEND_URL}/moderate`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text: audioText })
    });

    const result = await response.json();
    if (!result.allowed) {
        alert("Please speak in English only!");
    }
}

</script>
</html>
