<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>One-on-One Audio Call</title>
    <link rel="stylesheet" href="static/styles.css">
</head>
<body>
    <div class="container">
        <h1>One-on-One Audio Call</h1>
        <button id="startCall">Start Call</button>
        <audio id="remoteAudio" autoplay></audio>
        <p id="status">Waiting for a user...</p>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/peerjs/1.3.1/peerjs.min.js"></script>
    <script src="static/script.js"></script>
</body>
<style>
    body {
    font-family: Arial, sans-serif;
    text-align: center;
    background-color: #f4f4f4;
}

.container {
    width: 300px;
    margin: 100px auto;
    padding: 20px;
    background: white;
    box-shadow: 0px 0px 10px gray;
    border-radius: 10px;
}

button {
    padding: 10px 20px;
    font-size: 16px;
    margin-top: 10px;
    cursor: pointer;
    background: #007bff;
    color: white;
    border: none;
    border-radius: 5px;
}

button:hover {
    background: #0056b3;
}

</style>
<script>
    const startCallButton = document.getElementById("startCall");
const statusText = document.getElementById("status");
let peer;
let myPeerId;
let connectedPeerId;

startCallButton.addEventListener("click", async () => {
    try {
        const response = await fetch("/get_peer_id");
        const data = await response.json();
        myPeerId = data.peer_id;
        
        peer = new Peer(myPeerId);

        peer.on("open", (id) => {
            statusText.innerText = `Your ID: ${id}. Waiting for a match...`;
            findPeer();
        });

        peer.on("call", (call) => {
            navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
                call.answer(stream);
                call.on("stream", (remoteStream) => {
                    document.getElementById("remoteAudio").srcObject = remoteStream;
                    statusText.innerText = "Connected!";
                });
            });
        });
    } catch (error) {
        console.error("Error:", error);
    }
});

async function findPeer() {
    const response = await fetch("/find_peer");
    const data = await response.json();

    if (data.peer_id) {
        connectedPeerId = data.peer_id;
        connectToPeer(connectedPeerId);
    } else {
        statusText.innerText = "Waiting for another user...";
    }
}

function connectToPeer(peerId) {
    navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
        const call = peer.call(peerId, stream);
        call.on("stream", (remoteStream) => {
            document.getElementById("remoteAudio").srcObject = remoteStream;
            statusText.innerText = "Connected!";
        });
    });
}

// Gemini AI Integration for moderation
async function moderateAudio(audioText) {
    const response = await fetch("/moderate", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text: audioText })
    });

    const result = await response.json();
    if (!result.allowed) {
        alert("Please speak in English only!");
    }
}

</script>
</html>
